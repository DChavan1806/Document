- Microservice design patterns are architectural patterns that help in building and managing microservices. 
- These patterns address common problems faced when implementing a microservice-based architecture. 
- Here are some of the key microservice design patterns:
  1. Decomposition Patterns
     - Service per Bounded Context: Decompose services based on business domains or bounded contexts. Each microservice handles one part of the business functionality.
     - Service per Team: Organize services around teams. Each team is responsible for a microservice, allowing independent development and deployment.
  2. Database Patterns
     - Database per Service: Each microservice owns its database, ensuring loose coupling between services. This isolates failure and provides flexibility in scaling.
     - Shared Database: All services share a single database schema. This can simplify data consistency but increases coupling between services.
  3. Communication Patterns
     1. API Gateway: A single entry point for clients, which routes requests to the appropriate microservices. It can handle cross-cutting concerns like authentication, logging, and rate limiting.
     2. Chained Service: Microservices call each other directly, forming a chain to fulfill a request. This pattern works well when services have dependencies.
     3. Asynchronous Messaging: Use message brokers like Kafka or RabbitMQ for communication between services to avoid direct dependencies and improve scalability.
  4. Data Management Patterns
     1. CQRS (Command Query Responsibility Segregation): Separate read and write operations into different models to optimize performance and scalability.
     2. Event Sourcing: Capture changes to an application's state as a series of events. Microservices can rebuild their state from these events rather than storing the current state.
  5. Resilience Patterns
     - Circuit Breaker: Prevent a microservice from repeatedly calling another service that is likely to fail. After a threshold is reached, further calls are blocked for a period.
     - [circuit-breaker-pattern.md](../../Interview/circuit-breaker-pattern.md)
     - Retry: Automatically retry a failed operation, often combined with exponential backoff.
     - Bulkhead: Isolate resources for different microservices or operations to avoid failure in one part from impacting others.
  6. Discovery Patterns
     - Service Registry: Maintain a list of available services and their network locations, enabling microservices to discover each other.
     - Client-Side Discovery: Each microservice is responsible for contacting the service registry and selecting a service instance.
     - Server-Side Discovery: The service registry or a load balancer handles routing and service discovery.
  7. Security Patterns
     - Token-based Authentication: Use tokens like JWT (JSON Web Tokens) for authentication and authorization in stateless services.
     - OAuth2: A popular authentication framework used to grant clients secure access to services, often implemented with an API Gateway.
  8. Observability Patterns
     - Log Aggregation: Collect logs from all services and store them in a centralized location using tools like ELK or Splunk.
     - Distributed Tracing: Track requests as they flow through multiple microservices to troubleshoot and understand performance bottlenecks. Tools like Zipkin and Jaeger can help.
     - Health Check Endpoint: Each microservice provides an endpoint to monitor its health and notify orchestrators if something is wrong.
  9. Saga Pattern
     - Choreography: In a distributed transaction, each microservice involved in the transaction executes its part and triggers the next microservice via events.
     - Orchestration: A centralized service, called the orchestrator, coordinates the steps in the transaction and handles failure recovery.
  10. Anti-Corruption Layer
      - Use an adapter or translator to ensure that legacy systems or other microservices do not negatively impact the consistency or flexibility of your microservice.
- Each of these patterns addresses a specific challenge in microservice architecture, 
  such as communication, resilience, scalability, or data consistency, allowing for flexible and reliable systems.
  Handling exceptions in a nested microservice architecture can be complex due to the distributed nature of the system. Each microservice operates independently, and errors may occur at multiple levels as requests travel through different services. Therefore, it’s important to ensure that exceptions are properly handled, logged, and propagated across services in a way that maintains consistency and helps with troubleshooting.

**- Here’s how to handle exceptions effectively in a nested microservice architecture:**

1. Local Exception Handling (Within a Microservice) :
   - Each microservice should implement robust local exception handling to ensure that unexpected errors don’t crash the service. Common approaches include:
   1. Global Exception Handlers: Use global exception handlers (e.g., @ControllerAdvice in Spring Boot) to catch and manage exceptions at a global level within the service. This avoids scattering try-catch blocks throughout the code.
   2. Custom Exception Types: Define custom exceptions for different error scenarios (e.g., ResourceNotFoundException, ValidationException). These custom exceptions help to clearly distinguish between various error types and improve readability.
   3. Error Logging: Always log exceptions at the local level using tools like Logback, SLF4J, or Log4j, and send logs to centralized systems like ELK, Splunk, or Grafana for tracing and monitoring.

    @ControllerAdvice
    public class GlobalExceptionHandler {
        @ExceptionHandler(ResourceNotFoundException.class)
        public ResponseEntity<String> handleResourceNotFound(ResourceNotFoundException ex) {
            return new ResponseEntity<>("Resource Not Found", HttpStatus.NOT_FOUND);
        }

        @ExceptionHandler(Exception.class)
        public ResponseEntity<String> handleGenericException(Exception ex) {
            return new ResponseEntity<>("Internal Server Error", HttpStatus.INTERNAL_SERVER_ERROR);
        }
    }
2. Exception Propagation Between Microservices
   - When a microservice calls another microservice (e.g., via HTTP or messaging), exceptions need to be propagated appropriately.
     1. HTTP Status Codes: Use appropriate HTTP status codes to convey the nature of the exception. For example:
     2. 4xx for client-side errors (e.g., 404 for resource not found, 400 for bad request).
     3. 5xx for server-side errors (e.g., 500 for internal server errors, 503 for service unavailable).
     4. Custom Error Responses: Standardize error response structures (e.g., using a custom ErrorResponse object) across microservices. This helps clients (or upstream services) understand the error context and take appropriate action.

            {
            "timestamp": "2024-10-20T10:00:00Z",
            "status": 404,
            "error": "Resource Not Found",
            "message": "Item with ID 123 not found",
            "path": "/api/v1/items/123"
            }
     5. Retry Patterns: If a failure is transient (e.g., due to a temporary network issue or service unavailability), use retry patterns to reattempt the failed call. Combine this with a Circuit Breaker pattern to prevent overwhelming services with retries.

            @Retry(name = "itemService", fallbackMethod = "fallbackGetItem")
            public Item getItemById(Long id) {
            return itemService.getItemById(id);
            }

            public Item fallbackGetItem(Long id, Throwable ex) {
            return new Item(); // Return a default or cached response
            }
3. Distributed Exception Handling and Propagation
   - In a microservice architecture, exceptions may occur across multiple services, so handling them in a distributed manner is key.
   1. Exception Wrapping: When a downstream service throws an exception, it can be wrapped into a custom exception or error message by the upstream service. This way, upstream services can enrich the error message with additional context.
   
            try {
            response = restTemplate.getForObject("http://another-service/api/v1/resource", Resource.class);
            } catch (HttpClientErrorException ex) {
            throw new DownstreamServiceException("Error calling Another Service", ex);
            }
   2. Correlation IDs: To help trace errors across microservices, use a Correlation ID. Pass this ID with each request, allowing logs and exceptions to be traced back to the original request. Tools like Sleuth and Zipkin can help track request flows.

            String correlationId = MDC.get("correlationId");
            restTemplate.getForObject(url, responseType, correlationId);
4. Fallback Mechanism (Resilience Patterns)
   - In the event that a downstream service fails, provide fallback mechanisms to prevent cascading failures:
    1. Circuit Breaker: Use Circuit Breaker pattern (e.g., via Resilience4j or Hystrix) to stop propagating repeated failures. When the downstream service is failing consistently, the circuit breaker will trip and return a default response, reducing the load.
    2. Bulkhead: Isolate resources for different microservices to avoid one service failure cascading into others. By limiting resource sharing, the failure of one service won’t exhaust system resources.
5. Saga Pattern for Distributed Transactions
   - Handling exceptions in distributed transactions is challenging, especially when multiple services participate. The Saga pattern helps manage distributed transactions by either compensating actions or coordinating rollbacks.
    1. Choreography Saga: Each service knows how to compensate or rollback its operations. If an exception occurs, the services downstream will listen to the event and initiate their rollback operations.
    2. Orchestration Saga: A central orchestrator service manages the entire transaction flow. If any service throws an exception, the orchestrator commands compensating actions to undo previous operations.
6. Centralized Error Monitoring and Alerting
   1. Log Aggregation: Use centralized logging systems like ELK or Splunk to collect logs from all microservices. Correlate logs using correlation IDs or other contextual information.
   2. Alerting: Set up alerts for critical exceptions using monitoring tools like Prometheus, Grafana, or Kibana to detect failures early and respond accordingly.
7. Testing Exception Handling
   1. Unit Testing: Ensure all custom exception handlers and fallback mechanisms are covered with unit tests.
   2. Integration Testing: Test the communication between microservices, ensuring that exception handling logic works when failures occur in downstream services.
   3. Chaos Engineering: Implement chaos engineering (e.g., using Chaos Monkey) to simulate failures and test how well the microservices handle exceptions and recover.
- By combining these approaches, you can effectively manage exceptions across a nested microservice architecture, ensuring that errors are handled gracefully, well-communicated between services, and easy to trace and debug.